% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{6cm}
%
% and set <dim> to something 5cm or larger.

\title{Privacy-Preserving application using Homomorphic Encryption on NLP algorithms}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Jose Contreras \\
  University of Tartu \\
  \texttt{jose.angel.contreras.gedler@ut.ee} \\\And
  Karlos Taaniel Lillem√§e \\
  University of Tartu \\
  \texttt{karlos.taaniel.lillemae@ut.ee} \\}

\begin{document}
\maketitle




\section{Introduction}
Today's increasing use of Artificial Intelligence (AI) and Natural Language Processing (NLP) tools makes data privacy relevant, given that these tools often handle sensitive information. Therefore, it is necessary to include the secure handling of data as part of the design of any new AI tool, bearing in mind the existence of malicious entities capable of detecting system vulnerabilities and infiltrating information to carry out their purposes.

Moreover, for an AI project to gain the trust of its users, it must commit to safeguarding the privacy of the data shared by them. Scientific research in this field is very fertile, given the large amount of data circulating on the web every minute, much of which represents sensitive information that must be protected.

It is necessary to analyze the data processing stages to determine which privacy preservation techniques are best suited to each system, always seeking to ensure that the information provided by users is treated securely in all steps of the design and development of any system.


\section{Related Work}

A proposal that seeks to improve data privacy and protection with a methodology that uses NLP and unsupervised machine learning was made by \cite{Martinelli2020} to adequately manage sensitive and personal information.

The objective of \cite{Martinelli2020} was to create a valuable set of labeled data for training supervised machine learning algorithms to detect and classify sensitive privacy information in texts. The authors worked on Italian data and used a total of 1000 documents for the study, belonging to the health and justice sectors, 500 documents for each case, representing a minimal amount of data. However, the results were encouraging, and the authors suggest continuing in this direction to obtain new advances.

\cite{Klymenko_2022} address the alternative of using differential privacy in NLP. The authors clarify that this option is promising but has tremendous challenges. First, the data to be worked on must be evaluated or selected. The data will be unstructured, and it must be precisely known which information should be protected to avoid unnecessary computational expenses in protecting trivial data.

The mathematical solidity on which differential privacy is built has made it a good option for addressing security in this area. Additionally, it works on structured databases that contain the information that needs to be protected. \cite{Klymenko_2022} also present a generalization of differential privacy, known as metric differential privacy, which is a better alternative for NLP. They explain that when applying differential privacy, there is a perturbation of the original data, which designers control to work within a threshold that, despite modifying the original data to provide privacy, allows for practical work to obtain relevant information related to the original dataset, without compromising the privacy of the data.

An interesting approach was taken by \cite{Aono2016} by combining logistic regression with homomorphic encryption. Logistic regression is efficient in machine learning for classifying data, and the task of protecting such data using homomorphic encryption guarantees the integrity and confidentiality of the information.

Homomorphic Encryption (HE) is a cryptographic technique that allows the processing of encrypted data without decrypting it \cite{Armknecht2015}. This technique is based on the fact that the result of some mathematical operations on encrypted data is the same as if the operation were performed on the original data. This property allows mathematical operations on encrypted data without decrypting it.

The contribution of \cite{Aono2016} is the design of a secure and scalable system. They worked on the original logistic regression, transforming it into an equivalent regression using homomorphic encryption. Additionally, they have added instructions to add differential privacy to the system.

Recognizing the existence of reverse engineering tools that can extract the original information from systems designed with embedding techniques, \cite{Lee2022} proposed using homomorphic encryption on original data. Pre-trained BERT embeddings were used in their article, allowing the training of a logistic regression classifier. The results indicate that working with encrypted data enhances privacy and can assure users that malicious entities will use no private information. To this end, local privacy configuration was used, in which the user encodes their information before submitting it to a specific service provider.

Web page phishing remains a problem for cybersecurity as attackers continually refine their techniques, and users remain vulnerable to scams. \cite{Chou2020} analyzed images corresponding to both fake and legitimate web pages to establish their visual similarities and differences in order to differentiate them. In terms of privacy, they designed a system that uses homomorphic encryption and cloud computing, allowing the user to interact with the system by sending an encrypted image of the web page they wish to access to the cloud, which is examined to determine whether it is malicious or not. If found malicious, the user will receive an alert, avoiding any information theft or being scammed.

What is relevant for us from \cite{Chou2020} is the threat model, where the parties involved in the inference are semi-honest actors, which means that the attacker has access to the data but cannot modify it. \cite{Cryptogru_2021} follow this approach combining HE and Garbled Circuits into a hybrid structure for inference in Recurrent Neural Networks (RNN), a model called CryptoGRU. The model was tested on public datasets like Enron and IMDB, showing that the model can achieve high accuracy and latency.

THE-X is a tool that uses homomorphic encryption on transformers \cite{Chen2022}. It is a practical application that allowed them to conclude that while this type of encryption risks a percentage of performance, the privacy of the data is theoretically proven. Good results were obtained in sentiment analysis, paraphrasing, and text classification, and in future work, they plan to address performance issues.

There are many challenges in using homomorphic encryption in NLP, and \cite{Chen2022} summarizes the replacements needed to practically incorporate HE into modern NLP models. In particular, the most relevant issue is that HE operates only with basic additions and multiplication over the integers, or more precisely, over the ring of integers modulo a prime number. Thus, the model must be modified to work with integers, and the weights and biases must be quantized to integers. Despite the costs that this model imposes in terms of performance, this is one of the first practical applications of HE in transformers inference.


% Entries for the entire Anthology, followed by custom entries
\bibliography{references}
\bibliographystyle{acl_natbib}



\end{document}
